<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

<meta name="copyright" content="(C) Copyright 2022" />
<meta name="DC.rights.owner" content="(C) Copyright 2022" />
<meta name="generator" content="DITA-OT" /><meta name="DC.type" content="topic" />
<meta name="DC.title" content="gprecoverseg" />
<meta name="DC.format" content="XHTML" />
<meta name="DC.identifier" content="topic1" />
<link rel="stylesheet" type="text/css" href="../commonltr.css" />
<title>gprecoverseg</title>
</head>
<body id="topic1">

  <h1 class="title topictitle1" id="topic1__mb20941">gprecoverseg</h1>

  <div class="body">
    <p class="p">Recovers a primary or mirror segment instance that has been marked as down (if mirroring is
      enabled).</p>

    <div class="section" id="topic1__section2"><h2 class="title sectiontitle">Synopsis</h2>
      
      <pre class="pre codeblock"><code>gprecoverseg [[-p &lt;new_recover_host&gt;[,...]] | -i &lt;recover_config_file&gt;] [-d &lt;master_data_directory&gt;] 
             [-b &lt;segment_batch_size&gt;] [-B &lt;batch_size&gt;] [-F [-s]] [-a] [-q] 
	      [--hba-hostnames &lt;boolean&gt;] 
             [--no-progress] [-l &lt;logfile_directory&gt;]

gprecoverseg -r 

gprecoverseg -o &lt;output_recover_config_file&gt; 
             [-p &lt;new_recover_host&gt;[,...]]

gprecoverseg -? | -h | --help
        
gprecoverseg -v | --verbose

gprecoverseg --version</code></pre>
    </div>

    <div class="section" id="topic1__section3"><h2 class="title sectiontitle">Description</h2>In a system with mirrors enabled, the
        <code class="ph codeph">gprecoverseg</code> utility reactivates a failed segment instance and identifies
      the changed database files that require resynchronization. Once <code class="ph codeph">gprecoverseg</code>
      completes this process, the system goes into <code class="ph codeph">Not in Sync</code> mode until the
      recovered segment is brought up to date. The system is online and fully operational during
        resynchronization.<p class="p">During an incremental recovery (the <code class="ph codeph">-F</code> option is not
        specified), if <code class="ph codeph">gprecoverseg</code> detects a segment instance with mirroring
        disabled in a system with mirrors enabled, the utility reports that mirroring is disabled
        for the segment, does not attempt to recover that segment instance, and continues the
        recovery process. </p>
<p class="p">A segment instance can fail for several reasons, such as a host
        failure, network failure, or disk failure. When a segment instance fails, its status is
        marked as <code class="ph codeph">d</code> (down) in the Greenplum Database system catalog, and its mirror
        is activated in <code class="ph codeph">Not in Sync</code> mode. In order to bring the failed segment
        instance back into operation again, you must first correct the problem that made it fail in
        the first place, and then recover the segment instance in Greenplum Database using
          <code class="ph codeph">gprecoverseg</code>.</p>
<div class="note"><span class="notetitle">Note:</span>  If incremental recovery was
        not successful and the down segment instance data is not corrupted, contact VMware Support.
        </div>
<p class="p">Segment recovery using <code class="ph codeph">gprecoverseg</code> requires that you have an
        active mirror to recover from. For systems that do not have mirroring enabled, or in the
        event of a double fault (a primary and mirror pair both down at the same time) — you must
        take manual steps to recover the failed segment instances and then perform a system restart
        to bring the segments back online. For example, this command restarts a
        system.</p>
<pre class="pre codeblock"><code>gpstop -r</code></pre><p class="p">By default, a failed segment is recovered in
        place, meaning that the system brings the segment back online on the same host and data
        directory location on which it was originally configured. In this case, use the following
        format for the recovery configuration file (using
        <code class="ph codeph">-i</code>).</p>
<pre class="pre codeblock"><code>&lt;failed_host_address&gt;|&lt;port&gt;|&lt;data_directory&gt; </code></pre><p class="p">In
        some cases, this may not be possible (for example, if a host was physically damaged and
        cannot be recovered). In this situation, <code class="ph codeph">gprecoverseg</code> allows you to recover
        failed segments to a completely new host (using <code class="ph codeph">-p</code>), on an alternative data
        directory location on your remaining live segment hosts (using <code class="ph codeph">-s</code>), or by
        supplying a recovery configuration file (using <code class="ph codeph">-i</code>) in the following format.
        The word &lt;SPACE&gt; indicates the location of a required space. Do not add additional
        spaces.</p>
<pre class="pre codeblock"><code>&lt;failed_host_address&gt;|&lt;port&gt;|&lt;data_directory&gt;&lt;SPACE&gt;
&lt;recovery_host_address&gt;|&lt;port&gt;|&lt;data_directory&gt;
</code></pre><p class="p">See
        the <code class="ph codeph">-i</code> option below for details and examples of a recovery configuration
        file.</p>
<p class="p">The <code class="ph codeph">gp_segment_configuration</code> system catalog table can help you
        determine your current segment configuration so that you can plan your mirror recovery
        configuration. For example, run the following
        query:</p>
<pre class="pre codeblock"><code>=# SELECT dbid, content, address, port, datadir 
   FROM gp_segment_configuration
   ORDER BY dbid;</code></pre><p class="p">The
        new recovery segment host must be pre-installed with the Greenplum Database software and
        configured exactly the same as the existing segment hosts. A spare data directory location
        must exist on all currently configured segment hosts and have enough disk space to
        accommodate the failed segments.</p>
<p class="p">The recovery process marks the segment as up again in
        the Greenplum Database system catalog, and then initiates the resynchronization process to
        bring the transactional state of the segment up-to-date with the latest changes. The system
        is online and available during <code class="ph codeph">Not in Sync</code> mode. </p>
</div>

    <div class="section" id="topic1__section4"><h2 class="title sectiontitle">Options</h2>
      
      <dl class="dl parml">
        
          <dt class="dt pt dlterm">-a (do not prompt)</dt>

          <dd class="dd pd">Do not prompt the user for confirmation.</dd>

        
        
          <dt class="dt pt dlterm">-b <var class="keyword varname">segment_batch_size</var></dt>

          <dd class="dd pd">The maximum number of segments per host to operate on in parallel. Valid values are
              <code class="ph codeph">1</code> to <code class="ph codeph">128</code>. If not specified, the utility will start
            recovering up to 64 segments in parallel on each host.</dd>

        
        
          <dt class="dt pt dlterm">-B <var class="keyword varname">batch_size</var></dt>

          <dd class="dd pd">The number of hosts to work on in parallel. If not specified, the utility will start
            working on up to 16 hosts in parallel. Valid values are <code class="ph codeph">1</code> to
              <code class="ph codeph">64</code>. </dd>

        
        
          <dt class="dt pt dlterm">-d <var class="keyword varname">master_data_directory</var></dt>

          <dd class="dd pd">Optional. The master host data directory. If not specified, the value set for
              <code class="ph codeph">$MASTER_DATA_DIRECTORY</code> will be used.</dd>

        
        
          <dt class="dt pt dlterm">-F (full recovery)</dt>

          <dd class="dd pd">Optional. Perform a full copy of the active segment instance in order to recover the
            failed segment. The default is to only copy over the incremental changes that occurred
            while the segment was down. <div class="note warning"><span class="warningtitle">Warning:</span> A full recovery deletes the data
              directory of the down segment instance before copying the data from the active
              (current primary) segment instance. Before performing a full recovery, ensure that the
              segment failure did not cause data corruption and that any host segment disk issues
              have been fixed.<p class="p">Also, for a full recovery, the utility does not restore custom
                files that are stored in the segment instance data directory even if the custom
                files are also in the active segment instance. You must restore the custom files
                manually. For example, when using the <code class="ph codeph">gpfdists</code> protocol
                  (<code class="ph codeph">gpfdist</code> with SSL encryption) to manage external data, client
                certificate files are required in the segment instance
                  <code class="ph codeph">$PGDATA/gpfdists</code> directory. These files are not restored. For
                information about configuring <code class="ph codeph">gpfdists</code>, see <a class="xref" href="../../security-guide/topics/Encryption.html#gpfdist_connections">Encrypting gpfdist Connections</a>.</p>
</div>
 Use the <code class="ph codeph">-s</code> option to output a new line once per second
            for each segment. Alternatively, use the <code class="ph codeph">--no-progress</code> option to
            completely disable progress reports.</dd>

        
        
          <dt class="dt pt dlterm">--hba-hostnames <var class="keyword varname">boolean</var></dt>

          <dd class="dd pd">Optional. Controls whether this utility uses IP addresses or host names in the
              <code class="ph codeph">pg_hba.conf</code> file when updating this file with addresses that can
            connect to Greenplum Database. When set to 0 -- the default value -- this utility uses
            IP addresses when updating this file. When set to 1, this utility uses host names when
            updating this file. For consistency, use the same value that was specified for
              <code class="ph codeph">HBA_HOSTNAMES</code> when the Greenplum Database system was initialized. For
            information about how Greenplum Database resolves host names in the
              <code class="ph codeph">pg_hba.conf</code> file, see <a class="xref" href="../../admin_guide/client_auth.html" target="_blank">Configuring Client Authentication</a>.</dd>

        
        
          <dt class="dt pt dlterm">-i <var class="keyword varname">recover_config_file</var></dt>

          <dd class="dd pd">Specifies the name of a file with the details about failed segments to recover.
              <p class="p">Each line in the config file specifies a segment to recover. This line can have one
              of two formats. In the event of in-place (incremental) recovery, enter one group of
              pipe-delimited fields in the line. For example:</p>
<div class="p">
              <pre class="pre codeblock"><code>failedAddress|failedPort|failedDataDirectory</code></pre>
            </div>
<p class="p">For recovery to a new location, enter two groups of fields separated by a space
              in the line. The required space is indicated by &lt;SPACE&gt;. Do not add additional
              spaces.</p>
<div class="p">
              <pre class="pre codeblock"><code>failedAddress|failedPort|failedDataDirectory&lt;SPACE&gt;newAddress|
newPort|newDataDirectory</code></pre>
            </div>
<div class="p">
              <div class="note"><span class="notetitle">Note:</span> Lines beginning with <code class="ph codeph">#</code> are treated as comments and
                ignored.</div>

            </div>
<p class="p"><strong class="ph b">Examples</strong></p>
<p class="p"><strong class="ph b">In-place (incremental) recovery of a single
              mirror</strong></p>

            <pre class="pre codeblock"><code>sdw1-1|50001|/data1/mirror/gpseg16</code></pre>
            <p class="p"><strong class="ph b">Recovery of a single mirror to a new host</strong></p>

            <pre class="pre codeblock"><code>sdw1-1|50001|/data1/mirror/gpseg16&lt;SPACE&gt;sdw4-1|50001|/data1/recover1/gpseg16</code></pre>
            <p class="p"><strong class="ph b">Obtaining a Sample File</strong></p>

            <p class="p">You can use the <code class="ph codeph">-o</code> option to output a sample recovery configuration
              file to use as a starting point. The output file lists the currently invalid segments
              and their default recovery location. This file format can be used with the
                <code class="ph codeph">-i</code> option for in-place (incremental) recovery.</p>
</dd>

        
        
          <dt class="dt pt dlterm">-l <var class="keyword varname">logfile_directory</var></dt>

          <dd class="dd pd">The directory to write the log file. Defaults to <code class="ph codeph">~/gpAdminLogs</code>.</dd>

        
        
          <dt class="dt pt dlterm">-o <var class="keyword varname">output_recover_config_file</var></dt>

          <dd class="dd pd">Specifies a file name and location to output a sample recovery configuration file.
            This file can be edited to supply alternate recovery locations if needed. The following
            example outputs the default recovery configuration file:
            <pre class="pre codeblock"><code>$ gprecoverseg -o /home/gpadmin/recover_config_file</code></pre></dd>

        
        
          <dt class="dt pt dlterm">-p <var class="keyword varname">new_recover_host</var>[,...]</dt>

          <dd class="dd pd">Specifies a new host outside of the currently configured Greenplum Database array on
            which to recover invalid segments.</dd>

          <dd class="dd pd ddexpand">The new host must have the Greenplum Database software installed and configured, and
            have the same hardware and OS configuration as the current segment hosts (same OS
            version, locales, <code class="ph codeph">gpadmin</code> user account, data directory locations
            created, ssh keys exchanged, number of network interfaces, network interface naming
            convention, and so on). Specifically, the Greenplum Database binaries must be installed,
            the new host must be able to connect password-less with all segments including the
            Greenplum master, and any other Greenplum Database specific OS configuration parameters
            must be applied.</dd>

          <dd class="dd pd ddexpand">
            <div class="note"><span class="notetitle">Note:</span> In the case of multiple failed segment hosts, you can specify the hosts to recover
              with a comma-separated list. However, it is strongly recommended to recover one host
              at a time. If you must recover more than one host at a time, then it is critical to
              ensure that a double fault scenario does not occur, in which both the segment primary
              and corresponding mirror are offline.</div>

          </dd>

        
        
          <dt class="dt pt dlterm">-q (no screen output)</dt>

          <dd class="dd pd">Run in quiet mode. Command output is not displayed on the screen, but is still written
            to the log file.</dd>

        
        
          <dt class="dt pt dlterm">-r (rebalance segments)</dt>

          <dd class="dd pd">After a segment recovery, segment instances may not be returned to the preferred role
            that they were given at system initialization time. This can leave the system in a
            potentially unbalanced state, as some segment hosts may have more active segments than
            is optimal for top system performance. This option rebalances primary and mirror
            segments by returning them to their preferred roles. All segments must be valid and
            resynchronized before running <code class="ph codeph">gprecoverseg -r</code>. If there are any in
            progress queries, they will be cancelled and rolled back.</dd>

        
        
          <dt class="dt pt dlterm">-s (sequential progress)</dt>

          <dd class="dd pd">Show <code class="ph codeph">pg_basebackup</code> or <code class="ph codeph">pg_rewind</code> progress
            sequentially instead of in-place. Useful when writing to a file, or if a tty does not
            support escape sequences. The default is to show progress in-place. </dd>

        
        
          <dt class="dt pt dlterm">--no-progress</dt>

          <dd class="dd pd">Suppresses progress reports from the <code class="ph codeph">pg_basebackup</code> or
              <code class="ph codeph">pg_rewind</code> utility. The default is to display progress. </dd>

        
        
          <dt class="dt pt dlterm">-v | --verbose</dt>

          <dd class="dd pd">Sets logging output to verbose.</dd>

        
        
          <dt class="dt pt dlterm">--version</dt>

          <dd class="dd pd">Displays the version of this utility.</dd>

        
        
          <dt class="dt pt dlterm">-? | -h | --help</dt>

          <dd class="dd pd">Displays the online help.</dd>

        
      </dl>

    </div>

    <div class="section" id="topic1__section5"><h2 class="title sectiontitle">Examples</h2>
      <p class="p"><strong class="ph b">Example 1: Recover Failed Segments in Place</strong></p>

      <p class="p">Recover any failed segment instances in place:</p>

      <pre class="pre codeblock"><code>$ gprecoverseg</code></pre>
      <p class="p"><strong class="ph b">Example 2: Rebalance Failed Segments If Not in Preferred Roles</strong></p>

      <p class="p">First, verify that all segments are up and running,
        reysynchronization has completed, and there are segments <strong class="ph b">not</strong> in preferred
        roles:</p>

      <pre class="pre codeblock"><code>$ gpstate -e</code></pre>
      <p class="p">Then, if necessary, rebalance the segments:</p>
<pre class="pre codeblock"><code>$ gprecoverseg -r</code></pre>
      <p class="p"><strong class="ph b">Example 3: Recover Failed Segments to a Separate Host</strong></p>

      <p class="p">Recover any failed segment instances to a newly configured new segment host:</p>

        <pre class="pre codeblock"><code>$ gprecoverseg -i &lt;recover_config_file&gt;</code></pre>
    </div>

    <div class="section" id="topic1__section6"><h2 class="title sectiontitle">See Also</h2>
      
      <p class="p"><a class="xref" href="gpstart.html#topic1">gpstart</a>, <a class="xref" href="gpstop.html#topic1">gpstop</a></p>

    </div>

  </div>

</body>
</html>