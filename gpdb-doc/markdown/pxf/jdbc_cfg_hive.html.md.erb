---
title: Configuring the JDBC Connector for Hive (Optional)
---

You can use the PXF JDBC Connector to retrieve data from Hive. You can also use the "named query" feature to submit a custom SQL query to Hive and retrieve results using PXF JDBC connector.

This topic describes how to configure the PXF JDBC Connector to access Hive.

*If you do not plan to use the PXF JDBC Connector to access Hive, then you do not need to perform this procedure.*

## <a id="about_cfg"></a>About Configuring the JDBC Connector to Access Hive

The PXF JDBC Connector is installed with the `hive-jdbc-1.1.0.jar` and `hive-service-1.1.0.jar` JAR files.

When you configure a PXF JDBC server you must specify the JDBC driver class name, database URL, and client credentials just as you would when configuring a JDBC server to an SQL database.

Specify the following properties and values in the `jdbc-site.xml` server file when you want to access Hive via JDBC:

| Property       |  Value |
|----------------|--------|
| jdbc.driver | org.apache.hive.jdbc.HiveDriver |
| jdbc.url | jdbc:hive2://&lthiveserver2_host>:&lthiveserver2_port>/&ltdatabase> |


Other JDBC configuration property settings are determined by:

- whether or not the Hadoop cluster in which the Hive service is running is utilizing Kerberos authentication, and
- the values of certain HiveServer2 settings

If the Hive service is not running in a Kerberized environment use the `hive.server2.authentication` setting in `hive-site.xml` to determine futher configuration property settings:
    If `hive.server2.authentication` is set to `NOSASL`, no authentication will be performed by HiveServer2. You must add the following connection-level property to `jdbc-site.xml`:
        ``` xml
         <property>
             <name>jdbc.connection.property.auth</name>
             <value>noSasl</value>
         </property>
         ```
         Alternatively, you may choose to add `;auth=noSasl` to the `jdbc.url`.
    If `hive.server2.authentication` is set to `NONE`, or is not specified, you must set the `jdbc.user` property. The value to which you set the `jdbc.user` property is dependent about the `hive.server2.enable.doAs` setting in `hive-site.xml`:

        If `hive.server2.enable.doAs` is set to `TRUE` (the default), Hive runs Hadoop operations on behalf of the user connecting to Hive. You can either:
            Set `jdbc.user` to specify the user that has read permission on all Hive data being accessed by Greenplum Database. For example, to connect to Hive and run all requests as user `gpadmin`: ....
                ``` xml
                 <property>
                     <name>jdbc.user</name>
                     <value>gpadmin</value>
                 </property>
                 ```
    
            Or, turn on JDBC-level user impersonation so that PXF automatically uses the Greenplum user's username to connect to Hive:
                ``` xml
                 <property>
                     <name>jdbc.impersonation.jdbc</name>
                     <value>true</value>
                 </property>
                 ```
                 If you enable impersonation in this manner, do not explicitly specify the `jdbc.user` proprty or include the setting in `jdbc.url`.


        If `hive.server2.enable.doAs` is set to `FALSE`, Hive runs Hadoop operations as the user who started the HiveServer2 process, usually the user `hive`. PXF ignores the `jdbc.user` setting in this circumstance.


If the Hadoop cluster in which the Hive service is running is utilizing Kerberos authentication (`hive.server2.authentication` is set to `KERBEROS`):
    Ensure that you have configured the Hadoop cluster as the `default` server.
    Ensure that the `$PXF_CONF/servers/default/core-site.xml` file includes the following setting:
        ``` xml
        <property>
            <name>hadoop.security.authentication.</name>
            <value>kerberos</value>
        </property>
        ```

    You must add the `saslQop` property to `jdbc.url` and set it to match the value of the `hive.server2.thrift.sasl.qop` property in `hive-site.xml`. For example, if the `hive-site.xml` file includes the following property settting:
        ``` xml
        <property>
            <name>hive.server2.thrift.sasl.qop</name>
            <value>auth-conf</value>
        </property>
        ```
        You would add `;saslQup=auth-conf` to the `jdbc.url`.
       
    You must add the HiverServer2 `principal` name to the `jdbc.url`. For example:
        ``` pre
        jdbc:hive2://hs2server:10000/default;<b>principal=hive/hs2server@REALM</b>;saslQop=auth-conf
        ```

XXXXXXXXXX

### <a id="cfg_proc" class="no-quick-link"></a>Example Configuration Procedure

Ensure that you have initialized PXF before you configure a JDBC Connector server.

In this procedure, you name and add a PXF JDBC server configuration for a PostgreSQL database and synchronize the server configuration(s) to the Greenplum Database cluster.

1. Log in to your Greenplum Database master node:

    ``` shell
    $ ssh gpadmin@<gpmaster>
    ```

2. Choose a name for the JDBC server. You will provide the name to Greenplum users that you choose to allow to reference tables in the external SQL database as the configured user.

    **Note**: The server name `default` is reserved.

3. Create the `$PXF_HOME/servers/<server_name>` directory. For example, use the following command to create a JDBC server configuration named `pg_user1_testdb`:

    ``` shell
    gpadmin@gpmaster$ mkdir $PXF_CONF/servers/pg_user1_testdb
    ````

4. Copy the PXF JDBC server template file to the server configuration directory. For example:

    ``` shell
    gpadmin@gpmaster$ cp $PXF_CONF/templates/jdbc-site.xml $PXF_CONF/servers/pg_user1_testdb/
    ```
        
5. Open the template server configuration file in the editor of your choice, and provide appropriate property values for your environment. For example, if you are configuring access to a PostgreSQL database named `testdb` on a PostgreSQL instance running on the host named `pgserverhost` for the user named `user1`:

    ``` xml
    <?xml version="1.0" encoding="UTF-8"?>
    <configuration>
        <property>
            <name>jdbc.driver</name>
            <value>org.postgresql.Driver</value>
        </property>
        <property>
            <name>jdbc.url</name>
            <value>jdbc:postgresql://pgserverhost:5432/testdb</value>
        </property>
        <property>
            <name>jdbc.user</name>
            <value>user1</value>
        </property>
        <property>
            <name>jdbc.password</name>
            <value>changeme</value>
        </property>
    </configuration>
    ```
6. Save your changes and exit the editor.

7. Use the `pxf cluster sync` command to copy the new server configuration to the Greenplum Database cluster. For example:
    
    ``` shell
    gpadmin@gpmaster$ $GPHOME/pxf/bin/pxf cluster sync
    ```

