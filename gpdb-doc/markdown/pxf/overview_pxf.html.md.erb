---
title: Greenplum Platform Extension Framework (PXF)
---

<!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
-->

With the explosion of data stores and cloud services, data now resides across many disparate systems and in a variety of formats. Often, the data is classified by how often it is accessed - real-time or transactional (hot), less frequent (warm), or archival (cold) - and the location of and operations performed on the data.

The diagram below describes a data source that tracks monthly sales across many years. Real-time operational data is stored in MySQL. Data subject to analytic and business intelligence operations is housed in Greenplum Database. And the rarely accessed, archival data resides in AWS S3.

<img src="graphics/datatemp.png" class="image" width="630" alt="centered image"/>

When multiple, related data sets exist in external systems, it is often more efficient to join data sets remotely and return only the results, rather than negotiate the time and storage requirements of performing a rather expensive full data load operation. The *Greenplum Platform Extension Framework (PXF)*, a Greenplum extension that provides parallel, high throughput data access and federated query processing, provides this capability.

With PXF, you can use Greenplum and SQL to query these heterogeneous data sources:

- Hadoop versions 2 and 3, Hive versions 1, 2, and 3, HBase version 1.3.2
- Azure Blob Storage and Azure Data Lake
- AWS S3
- Minio
- Google Cloud Storage
- SQL databases including Apache Ignite, Hive, MySQL, ORACLE, and PostgreSQL (via JDBC)

And these data formats:

- Avro, AvroSequenceFile
- JSON
- ORC
- Parquet
- RCFile
- SequenceFile
- Text (plain, delimited, embedded line feeds)

## <a id="basic_usage"></a> Basic Usage

You use PXF to map data from an external source to a Greenplum Database *external table* definition. You can then use the PXF external table and SQL to:

- Perform queries on the external data, leaving the referenced data in place on the remote system.
- Load a subset of the external data into Greenplum Database.
- Run complex queries on local data residing in Greenplum tables and remote data referenced via PXF external tables.
- Write data to the external data source.

Check out the [PXF introduction](intro_pxf.html) for a high level overview important PXF concepts.

## <a id="getstart_cfg"></a> Get Started Configuring PXF

The Greenplum Database administrator manages PXF, Greenplum Database user privileges, and external data source configuration. Tasks include:

- [Installing](about_pxf_dir.html), [configuring](instcfg_pxf.html), [starting](cfginitstart_pxf.html), [monitoring](monitor_pxf.html), and [troubleshooting](troubleshooting_pxf.html) the PXF service.
- Managing PXF [upgrade](upgrade_pxf_6x.html) and [migration](migrate_5to6.html).
- [Configuring](cfg_server.html) and publishing one or more server definitions for each external data source. This definition specifies the location of, and access credentials to, the external data source. 
- Considering and [configuring](using_pxf.html) Greenplum user access to PXF and PXF external tables.

## <a id="getstart_user"></a> Get Started Using PXF

A Greenplum Database user [creates](intro_pxf.html#create_external_table) a PXF external table that references a file or other data in the external data source, and uses the external table to query or load the external data in Greenplum:

- [Accessing Hadoop with PXF](access_hdfs.html) describes the operations required when the data resides in Hadoop.
- [Accessing Azure, Google Cloud Storage, Minio, and S3 Object Stores with PXF](access_objstore.html) describes the operations required when the data resides in an object store.
- [Accessing an SQL Database with PXF](jdbc_pxf.html) describes the operations required when the data resides in an external SQL database.

