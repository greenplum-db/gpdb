---
title: Introducing the PXF Extension Framework
---

The Greenplum Database PXF Extension Framework is based on [Apache HAWQ PXF](https://cwiki.apache.org/confluence/display/HAWQ/PXF). 

You can use the Greenplum Database PXF Extension Framework to access external data sources as though they were local to your Greenplum Database deployment.

## <a id="intro_pxf_overview"></a>Overview

Data managed by your organization may already reside in external sources. The Greenplum Database PXF Extension Framework (PXF) provides you access to this external data via built-in connectors that map an external data source to a Greenplum Database table definition. 

PXF is installed with HDFS and Hive connectors. These connectors enable you to read external HDFS file system and Hive table data in text, Avro, RCFile, Parquet, SequenceFile, and ORC formats.

## <a id="intro_pxf_arch"></a>Architecture
    
The PXF Extension Framework is composed of a Greenplum Database protocol and associated C client library plus a Java service. These components work together to provide you access to data stored in sources external to your Greenplum Database deployment. 

Your Greenplum Database deployment consists of a master node and multiple segment hosts. After you configure and initialize PXF, you start a single PXF JVM process on each Greenplum Database segment host. This PXF process (referred to as the PXF agent) will spawn a thread for each segment instance on that segment host that is serving a PXF external table query. Multiple segment instances on each segment host communicate with PXF in parallel, and the PXF agents on multiple hosts communicate with HDFS in parallel.

When a user or application performs a query on a PXF external table referencing an HDFS file, the Greenplum Database master node dispatches the query to one or more segment instances. Each segment instance contacts the PXF agent running on its host. When it receives the request from a segment instance, the PXF agent:

- Spawns a thread for the segment instance.
- Invokes the HDFS Java API to request metadata information for the HDFS file from the HDFS NameNode. 
- Provides the metadata information returned by the HDFS NameNode to the segment instance.  

A segment instance uses its Greenplum Database `gp_segment_id` and the file block information described in the metadata to assign itself a specific portion of the query data. The segment instance then sends a request to the PXF agent to read the assigned data. This data may reside on one or more HDFS DataNodes.

The PXF agent invokes the HDFS Java API to read the data. The HDFS API routes the request to the appropriate HDFS DataNode(s). The PXF agent will deliver the data returned by the DataNodes to the segment instance. Finally, the segment instance delivers its portion of the data to the Greenplum Database master node. This communication occurs across all segments in parallel.


<span class="figtitleprefix">Figure: </span>PXF Extension Framework Architecture

<img src="graphics/pxfarch.png" class="image" />
