-- start_matchsubs
-- m/ Gather Motion [12]:1  \(slice1; segments: [12]\)/
-- s/ Gather Motion [12]:1  \(slice1; segments: [12]\)/ Gather Motion XXX/
-- m/Memory Usage: \d+\w?B/
-- s/Memory Usage: \d+\w?B/Memory Usage: ###B/
-- m/Buckets: \d+/
-- s/Buckets: \d+/Buckets: ###/
-- m/Batches: \d+/
-- s/Batches: \d+/Batches: ###/
-- end_matchsubs
CREATE TEMP TABLE empty_table(a int);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'a' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
-- We used to incorrectly report "never executed" for a node that returns 0 rows
-- from every segment. This was misleading because "never executed" should
-- indicate that the node was never executed by its parent.
-- explain_processing_off
EXPLAIN (ANALYZE, TIMING OFF, COSTS OFF, SUMMARY OFF) SELECT a FROM empty_table;
                            QUERY PLAN                            
------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3) (actual rows=0 loops=1)
   ->  Seq Scan on empty_table (actual rows=0 loops=1)
 Optimizer: Pivotal Optimizer (GPORCA)
(3 rows)

-- explain_processing_on
-- For a node that is truly never executed, we still expect "never executed" to
-- be reported
-- explain_processing_off
EXPLAIN (ANALYZE, TIMING OFF, COSTS OFF, SUMMARY OFF) SELECT t1.a FROM empty_table t1 join empty_table t2 on t1.a = t2.a;
                                   QUERY PLAN                                    
---------------------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3) (actual rows=0 loops=1)
   ->  Hash Join (actual rows=0 loops=1)
         Hash Cond: (empty_table.a = empty_table_1.a)
         ->  Seq Scan on empty_table (never executed)
         ->  Hash (actual rows=0 loops=1)
               Buckets: 524288  Batches: 1  Memory Usage: 4096kB
               ->  Seq Scan on empty_table empty_table_1 (actual rows=0 loops=1)
 Optimizer: Pivotal Optimizer (GPORCA)
(8 rows)

-- explain_processing_on
-- If all QEs hit errors when executing sort, we might not receive stat data for sort.
-- rethrow error before print explain info.
create extension if not exists gp_inject_fault;
create table sort_error_test1(tc1 int, tc2 int);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'tc1' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
create table sort_error_test2(tc1 int, tc2 int);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'tc1' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
insert into sort_error_test1 select i,i from generate_series(1,20) i;
select gp_inject_fault('explain_analyze_sort_error', 'error', dbid)
    from gp_segment_configuration where role = 'p' and content > -1;
 gp_inject_fault 
-----------------
 Success:
 Success:
 Success:
(3 rows)

EXPLAIN analyze insert into sort_error_test2 select * from sort_error_test1 order by 1;
ERROR:  fault triggered, fault name:'explain_analyze_sort_error' fault type:'error'  (seg0 127.0.1.1:7002 pid=103209)
select count(*) from sort_error_test2;
 count 
-------
     0
(1 row)

select gp_inject_fault('explain_analyze_sort_error', 'reset', dbid)
    from gp_segment_configuration where role = 'p' and content > -1;
 gp_inject_fault 
-----------------
 Success:
 Success:
 Success:
(3 rows)

drop table sort_error_test1;
drop table sort_error_test2;
-- The statistics for modifying CTEs used to be reported as "never executed",
-- when all plan nodes were executed and some stat information was expected.
-- Test QD recieving the stats from all slices and showing it in explain output.
--start_ignore
DROP TABLE IF EXISTS with_dml;
NOTICE:  table "with_dml" does not exist, skipping
--end_ignore
CREATE TABLE with_dml (i int, j int) DISTRIBUTED BY (i);
EXPLAIN (ANALYZE, TIMING OFF, COSTS OFF, SUMMARY OFF)
WITH cte AS (
    INSERT INTO with_dml SELECT i, i * 100 FROM generate_series(1,5) i
    RETURNING i
) SELECT * FROM cte;
                                     QUERY PLAN                                     
------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3) (actual rows=5 loops=1)
   ->  Insert on with_dml (actual rows=3 loops=1)
         ->  Redistribute Motion 1:3  (slice2; segments: 1) (actual rows=3 loops=1)
               Hash Key: i.i
               ->  Function Scan on generate_series i (actual rows=5 loops=1)
 Optimizer: Postgres query optimizer
(6 rows)

EXPLAIN (ANALYZE, TIMING OFF, COSTS OFF, SUMMARY OFF)
WITH cte AS (
    UPDATE with_dml SET j = j + 1
    RETURNING i
) SELECT * FROM cte;
                            QUERY PLAN                            
------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3) (actual rows=5 loops=1)
   ->  Update on with_dml (actual rows=3 loops=1)
         ->  Seq Scan on with_dml (actual rows=3 loops=1)
 Optimizer: Postgres query optimizer
(4 rows)

EXPLAIN (ANALYZE, TIMING OFF, COSTS OFF, SUMMARY OFF)
WITH cte AS (
    DELETE FROM with_dml WHERE i > 0
    RETURNING i
) SELECT * FROM cte;
                            QUERY PLAN                            
------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3) (actual rows=5 loops=1)
   ->  Delete on with_dml (actual rows=3 loops=1)
         ->  Seq Scan on with_dml (actual rows=3 loops=1)
               Filter: (i > 0)
 Optimizer: Postgres query optimizer
(5 rows)

DROP TABLE with_dml;
