-- start_ignore
\! gpconfig -c create_restartpoint_on_chpt_record_replay -v on --skipvalidation;
20190712:14:08:38:032229 gpconfig:Weinan-Pivotal-Mac:wwang-[INFO]:-completed successfully with parameters '-c create_restartpoint_on_chpt_record_replay -v on --skipvalidation'
\! gpstop -u;
20190712:14:08:39:032286 gpstop:Weinan-Pivotal-Mac:wwang-[INFO]:-Starting gpstop with args: -u
20190712:14:08:39:032286 gpstop:Weinan-Pivotal-Mac:wwang-[INFO]:-Gathering information and validating the environment...
20190712:14:08:39:032286 gpstop:Weinan-Pivotal-Mac:wwang-[INFO]:-Obtaining Greenplum Master catalog information
20190712:14:08:39:032286 gpstop:Weinan-Pivotal-Mac:wwang-[INFO]:-Obtaining Segment details from master...
20190712:14:08:39:032286 gpstop:Weinan-Pivotal-Mac:wwang-[INFO]:-Greenplum Version: 'postgres (Greenplum Database) 7.0.0-alpha.0+dev.508.gbfe8325ded build dev'
20190712:14:08:39:032286 gpstop:Weinan-Pivotal-Mac:wwang-[INFO]:-Signalling all postmaster processes to reload
create language plpythonu;
-- end_ignore
CREATE OR REPLACE FUNCTION get_tablespace_version_directory_name()
    RETURNS TEXT
AS '@abs_builddir@/regress.so', 'get_tablespace_version_directory_name'
    LANGUAGE C;
CREATE OR REPLACE FUNCTION stat_db_objects(datname text, spcname text)
    RETURNS TABLE (dbid int2, relfilenode_dboid_relative_path text, size int)
    VOLATILE LANGUAGE plpythonu
AS
$fn$
import os
db_instances = {}
PG_DEFAULT_TSOID = 1663
PG_GLOBAL_TSOID = 1664

result = plpy.execute("SELECT get_tablespace_version_directory_name() AS tablespace_version_dir_name;")
tablespace_version_dir_name = result[0]['tablespace_version_dir_name']

result = plpy.execute("SELECT oid AS dboid FROM pg_database WHERE datname='%s'" % datname)
dboid = result[0]['dboid']

result = plpy.execute("SELECT oid AS tsoid FROM pg_tablespace WHERE spcname='%s'" % spcname)
tsoid = result[0]['tsoid']

result = plpy.execute("select dbid, datadir from gp_segment_configuration;")
for col in range(0, result.nrows()):
    db_instances[result[col]['dbid']] = result[col]['datadir']

rows = []
for dbid, datadir in db_instances.items():
    relative_path_to_dboid_dir = ''
    if tsoid == PG_DEFAULT_TSOID:
        absolute_path_to_dboid_dir = '%s/base/%d' % (datadir, dboid)
    elif tsoid == PG_GLOBAL_TSOID:
        plpy.error("You can't have a database within the global tablespace")
    else:
        absolute_path_to_dboid_dir = '%(datadir)s/pg_tblspc/%(tsoid)d/%(tablespace_version_dir_name)s/%(dboid)d' % {
            'datadir': datadir,
            'tsoid': tsoid,
            'tablespace_version_dir_name': tablespace_version_dir_name,
            'dboid': dboid
        }

    try:
        for relfilenode in os.listdir(absolute_path_to_dboid_dir):
            relfilenode_absolute_path = absolute_path_to_dboid_dir + '/' + relfilenode
            size_relfilenode = os.stat(relfilenode_absolute_path).st_size
            row = {
                'relfilenode_dboid_relative_path': '%d/%s' % (dboid, relfilenode),
                'dbid': dbid,
                'size': size_relfilenode
            }

            rows.append(row)
    except OSError:
        plpy.notice("dboid dir for database %s does not exist on dbid = %d" % (datname, dbid))
        rows.append({
            'relfilenode_dboid_relative_path': None,
            'dbid': dbid,
            'size': None
        })

return rows
$fn$;
--list all database oid relevant directories in all node(master, segments, mirrors, etc.)
CREATE OR REPLACE FUNCTION db_dirs(dboid oid) RETURNS setof text
  STRICT STABLE LANGUAGE plpythonu
as $$
import os
bash_cmd = "find " + os.getcwd() + "/../../ " + "-name %d -type d"
p = os.popen(bash_cmd % dboid)
return p.readlines()
$$;
--this group udf help test case wait mirror cacheup
CREATE OR REPLACE FUNCTION insert_noop_xlog_record_master() RETURNS VOID AS
'@abs_builddir@/regress.so', 'insert_noop_xlog_record'
    LANGUAGE C EXECUTE ON MASTER;
CREATE OR REPLACE FUNCTION insert_noop_xlog_record_all_segments() RETURNS SETOF VOID AS
'@abs_builddir@/regress.so', 'insert_noop_xlog_record'
    LANGUAGE C EXECUTE ON ALL SEGMENTS;
CREATE OR REPLACE FUNCTION insert_noop_xlog_record() RETURNS VOID AS $$
BEGIN
    PERFORM insert_noop_xlog_record_master();
    PERFORM insert_noop_xlog_record_all_segments();
END;
$$LANGUAGE plpgsql;
CREATE OR REPLACE FUNCTION force_mirrors_to_catch_up() RETURNS VOID AS $$
BEGIN
    PERFORM gp_inject_fault2('after_xlog_redo_noop', 'sleep', dbid, hostname, port) FROM gp_segment_configuration WHERE role='m';
    PERFORM insert_noop_xlog_record();
    PERFORM gp_wait_until_triggered_fault2('after_xlog_redo_noop', 1, dbid, hostname, port) FROM gp_segment_configuration WHERE role='m';
    PERFORM gp_inject_fault2('after_xlog_redo_noop', 'reset', dbid, hostname, port) FROM gp_segment_configuration WHERE role='m';
END;
$$ LANGUAGE plpgsql;
create database db100;
create database db101;
\! psql -d db100 -c "create table test1(a int, b text)"
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'a' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
CREATE TABLE
\! psql -d db100 -c "insert into test1 values (1, '111'), (2, '222'), (3, '333')"
INSERT 0 3
\! psql -d db101 -c "create table test1(a int, b text)"
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'a' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
CREATE TABLE
\! psql -d db101 -c "insert into test1 values (1, '111'), (2, '222'), (3, '333')"
INSERT 0 3
--
--CASE 0: drop well
--
drop database db101;
-- Wait until replay_location = flush_location.
select force_mirrors_to_catch_up();
 force_mirrors_to_catch_up 
---------------------------
 
(1 row)

select count(*) from pg_database where datname='db101';
 count 
-------
     0
(1 row)

\! psql -d db101 -c "select * from test1"
psql: FATAL:  database "db101" does not exist
select count(*)=0 from (select db_dirs(oid) from pg_database where datname='db101') as foo; 
 ?column? 
----------
 t
(1 row)

CREATE TABLE before_drop AS SELECT * FROM stat_db_objects('db100', 'pg_default');
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column(s) named 'dbid' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
--
--CASE 1: error on segment after XLOG_DBASE_DROP
--
--reset status
select gp_inject_fault2('all', 'reset', dbid, hostname, port) from gp_segment_configuration;
 gp_inject_fault2 
------------------
 Success:
 Success:
 Success:
 Success:
 Success:
 Success:
 Success:
 Success:
(8 rows)

select gp_inject_fault2('dropdb_after_xlog_dbase_drop', 'error', dbid, hostname, port)
from gp_segment_configuration where content=0 and role='p';
 gp_inject_fault2 
------------------
 Success:
(1 row)

-- should fail
drop database db100;
ERROR:  fault triggered, fault name:'dropdb_after_xlog_dbase_drop' fault type:'error'  (seg0 10.34.49.130:25432 pid=32307)
-- Wait until replay_location = flush_location.
select force_mirrors_to_catch_up();
 force_mirrors_to_catch_up 
---------------------------
 
(1 row)

select count(*) from pg_database where datname='db100';
 count 
-------
     1
(1 row)

\! psql -d db100 -c "select * from test1"
 a |  b  
---+-----
 2 | 222
 3 | 333
 1 | 111
(3 rows)

select count(*)=0 from (select db_dirs(oid) from pg_database where datname='db100') as foo; 
 ?column? 
----------
 f
(1 row)

CREATE TABLE after_drop AS SELECT * FROM stat_db_objects('db100', 'pg_default');
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column(s) named 'dbid' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
SELECT * FROM ((SELECT * FROM before_drop) EXCEPT (SELECT * FROM after_drop)) r WHERE relfilenode_dboid_relative_path NOT LIKE '%pg_internal.init';
 dbid | relfilenode_dboid_relative_path | size 
------+---------------------------------+------
(0 rows)

DROP TABLE after_drop;
-- start_ignore
select count(*) from (select db_dirs(oid) from pg_database where datname='db100') as foo; 
 count 
-------
     8
(1 row)

-- end_ignore
--
--CASE 2: error on master after XLOG_DBASE_DROP
--
--reset status
select gp_inject_fault2('all', 'reset', dbid, hostname, port) from gp_segment_configuration;
 gp_inject_fault2 
------------------
 Success:
 Success:
 Success:
 Success:
 Success:
 Success:
 Success:
 Success:
(8 rows)

select gp_inject_fault2('dropdb_after_xlog_dbase_drop', 'error', dbid, hostname, port)
from gp_segment_configuration where content=-1 and role='p';
 gp_inject_fault2 
------------------
 Success:
(1 row)

-- should fail
drop database db100;
ERROR:  fault triggered, fault name:'dropdb_after_xlog_dbase_drop' fault type:'error'
-- Wait until replay_location = flush_location.
select force_mirrors_to_catch_up();
 force_mirrors_to_catch_up 
---------------------------
 
(1 row)

select count(*) from pg_database where datname='db100';
 count 
-------
     1
(1 row)

\! psql -d db100 -c "select * from test1"
 a |  b  
---+-----
 2 | 222
 3 | 333
 1 | 111
(3 rows)

select count(*)=0 from (select db_dirs(oid) from pg_database where datname='db100') as foo; 
 ?column? 
----------
 f
(1 row)

CREATE TABLE after_drop AS SELECT * FROM stat_db_objects('db100', 'pg_default');
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column(s) named 'dbid' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
SELECT * FROM ((SELECT * FROM before_drop) EXCEPT (SELECT * FROM after_drop)) r WHERE relfilenode_dboid_relative_path NOT LIKE '%pg_internal.init';
 dbid | relfilenode_dboid_relative_path | size 
------+---------------------------------+------
(0 rows)

DROP TABLE after_drop;
-- start_ignore
select count(*) from (select db_dirs(oid) from pg_database where datname='db100') as foo; 
 count 
-------
     8
(1 row)

-- end_ignore
--
--CASE 3: error on segment before XLOG_XACT_PREPARED
--
--reset status
select gp_inject_fault2('all', 'reset', dbid, hostname, port) from gp_segment_configuration;
 gp_inject_fault2 
------------------
 Success:
 Success:
 Success:
 Success:
 Success:
 Success:
 Success:
 Success:
(8 rows)

select gp_inject_fault2('before_xlog_xact_prepare', 'error', dbid, hostname, port)
from gp_segment_configuration where content=0 and role='p';
 gp_inject_fault2 
------------------
 Success:
(1 row)

-- should fail
drop database db100;
ERROR:  fault triggered, fault name:'before_xlog_xact_prepare' fault type:'error'  (seg0 10.34.49.130:25432 pid=32307)
-- Wait until replay_location = flush_location.
select force_mirrors_to_catch_up();
 force_mirrors_to_catch_up 
---------------------------
 
(1 row)

select count(*) from pg_database where datname='db100';
 count 
-------
     1
(1 row)

\! psql -d db100 -c "select * from test1"
 a |  b  
---+-----
 2 | 222
 3 | 333
 1 | 111
(3 rows)

select count(*)=0 from (select db_dirs(oid) from pg_database where datname='db100') as foo; 
 ?column? 
----------
 f
(1 row)

CREATE TABLE after_drop AS SELECT * FROM stat_db_objects('db100', 'pg_default');
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column(s) named 'dbid' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
SELECT * FROM ((SELECT * FROM before_drop) EXCEPT (SELECT * FROM after_drop)) r WHERE relfilenode_dboid_relative_path NOT LIKE '%pg_internal.init';
 dbid | relfilenode_dboid_relative_path | size 
------+---------------------------------+------
(0 rows)

DROP TABLE after_drop;
-- start_ignore
select count(*) from (select db_dirs(oid) from pg_database where datname='db100') as foo; 
 count 
-------
     8
(1 row)

-- end_ignore
--
--CASE 4: panic on segment before XLOG_XACT_PREPARED
--
--reset status
select gp_inject_fault2('all', 'reset', dbid, hostname, port) from gp_segment_configuration;
 gp_inject_fault2 
------------------
 Success:
 Success:
 Success:
 Success:
 Success:
 Success:
 Success:
 Success:
(8 rows)

select gp_inject_fault2('before_xlog_xact_prepare', 'panic', dbid, hostname, port)
from gp_segment_configuration where content=0 and role='p';
 gp_inject_fault2 
------------------
 Success:
(1 row)

select gp_inject_fault2('fts_probe', 'skip', dbid, hostname, port)
from gp_segment_configuration where content=0 and role='p';
 gp_inject_fault2 
------------------
 Success:
(1 row)

-- should fail
drop database db100;
ERROR:  fault triggered, fault name:'before_xlog_xact_prepare' fault type:'panic'  (seg0 10.34.49.130:25432 pid=32307)
-- Wait until replay_location = flush_location.
select force_mirrors_to_catch_up();
 force_mirrors_to_catch_up 
---------------------------
 
(1 row)

select count(*) from pg_database where datname='db100';
 count 
-------
     1
(1 row)

\! psql -d db100 -c "select * from test1"
 a |  b  
---+-----
 1 | 111
 2 | 222
 3 | 333
(3 rows)

select count(*)=0 from (select db_dirs(oid) from pg_database where datname='db100') as foo; 
 ?column? 
----------
 f
(1 row)

CREATE TABLE after_drop AS SELECT * FROM stat_db_objects('db100', 'pg_default');
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column(s) named 'dbid' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
SELECT * FROM ((SELECT * FROM before_drop) EXCEPT (SELECT * FROM after_drop)) r WHERE relfilenode_dboid_relative_path NOT LIKE '%pg_internal.init';
 dbid | relfilenode_dboid_relative_path | size 
------+---------------------------------+------
(0 rows)

DROP TABLE after_drop;
-- start_ignore
select count(*) from (select db_dirs(oid) from pg_database where datname='db100') as foo; 
 count 
-------
     8
(1 row)

-- end_ignore
--
--CASE 5: panic on segment after XLOG_XACT_PREPARED_FLUSHED
--
--reset status
select gp_inject_fault2('all', 'reset', dbid, hostname, port) from gp_segment_configuration;
 gp_inject_fault2 
------------------
 Success:
 Success:
 Success:
 Success:
 Success:
 Success:
 Success:
 Success:
(8 rows)

select gp_inject_fault2('after_xlog_xact_prepare_flushed', 'panic', dbid, hostname, port)
from gp_segment_configuration where content=0 and role='p';
 gp_inject_fault2 
------------------
 Success:
(1 row)

select gp_inject_fault2('fts_probe', 'skip', dbid, hostname, port)
from gp_segment_configuration where content=0 and role='p';
 gp_inject_fault2 
------------------
 Success:
(1 row)

-- should fail
drop database db100;
ERROR:  fault triggered, fault name:'after_xlog_xact_prepare_flushed' fault type:'panic'  (seg0 10.34.49.130:25432 pid=32454)
-- Wait until replay_location = flush_location.
select force_mirrors_to_catch_up();
 force_mirrors_to_catch_up 
---------------------------
 
(1 row)

select count(*) from pg_database where datname='db100';
 count 
-------
     1
(1 row)

\! psql -d db100 -c "select * from test1"
 a |  b  
---+-----
 1 | 111
 2 | 222
 3 | 333
(3 rows)

select count(*)=0 from (select db_dirs(oid) from pg_database where datname='db100') as foo; 
 ?column? 
----------
 f
(1 row)

CREATE TABLE after_drop AS SELECT * FROM stat_db_objects('db100', 'pg_default');
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column(s) named 'dbid' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
SELECT * FROM ((SELECT * FROM before_drop) EXCEPT (SELECT * FROM after_drop)) r WHERE relfilenode_dboid_relative_path NOT LIKE '%pg_internal.init';
 dbid | relfilenode_dboid_relative_path | size 
------+---------------------------------+------
(0 rows)

DROP TABLE after_drop;
--
--CASE 6: panic on segment before XLOG_XACT_COMMIT_PREPARED
--
--reset status
select gp_inject_fault2('all', 'reset', dbid, hostname, port) from gp_segment_configuration;
 gp_inject_fault2 
------------------
 Success:
 Success:
 Success:
 Success:
 Success:
 Success:
 Success:
 Success:
(8 rows)

select gp_inject_fault2('before_xlog_xact_commit_prepared', 'panic', dbid, hostname, port)
from gp_segment_configuration where content=0 and role='p';
 gp_inject_fault2 
------------------
 Success:
(1 row)

select gp_inject_fault2('fts_probe', 'skip', dbid, hostname, port)
from gp_segment_configuration where content=0 and role='p';
 gp_inject_fault2 
------------------
 Success:
(1 row)

-- failed, retry and success
drop database db100;
WARNING:  the distributed transaction 'Commit Prepared' broadcast failed to one or more segments for gid = 1562901053-0000001379.  Retrying ... try 1
NOTICE:  Releasing segworker group to retry broadcast.
-- Wait until replay_location = flush_location.
select force_mirrors_to_catch_up();
 force_mirrors_to_catch_up 
---------------------------
 
(1 row)

select count(*) from pg_database where datname='db100';
 count 
-------
     0
(1 row)

\! psql -d db100 -c "select * from test1"
psql: FATAL:  database "db100" does not exist
set gp_select_invisible to on;
select count(*)=0 from (select db_dirs(oid) from pg_database where datname='db100') as foo; 
 ?column? 
----------
 t
(1 row)

set gp_select_invisible to off;
-- start_ignore
select gp_inject_fault2('all', 'reset', dbid, hostname, port) from gp_segment_configuration;
 gp_inject_fault2 
------------------
 Success:
 Success:
 Success:
 Success:
 Success:
 Success:
 Success:
 Success:
(8 rows)

\! gpconfig -r create_restartpoint_on_chpt_record_replay --skipvalidation;
20190712:14:09:00:032660 gpconfig:Weinan-Pivotal-Mac:wwang-[INFO]:-completed successfully with parameters '-r create_restartpoint_on_chpt_record_replay --skipvalidation'
\! gpstop -u;
20190712:14:09:01:032723 gpstop:Weinan-Pivotal-Mac:wwang-[INFO]:-Starting gpstop with args: -u
20190712:14:09:01:032723 gpstop:Weinan-Pivotal-Mac:wwang-[INFO]:-Gathering information and validating the environment...
20190712:14:09:01:032723 gpstop:Weinan-Pivotal-Mac:wwang-[INFO]:-Obtaining Greenplum Master catalog information
20190712:14:09:01:032723 gpstop:Weinan-Pivotal-Mac:wwang-[INFO]:-Obtaining Segment details from master...
20190712:14:09:01:032723 gpstop:Weinan-Pivotal-Mac:wwang-[INFO]:-Greenplum Version: 'postgres (Greenplum Database) 7.0.0-alpha.0+dev.508.gbfe8325ded build dev'
20190712:14:09:01:032723 gpstop:Weinan-Pivotal-Mac:wwang-[INFO]:-Signalling all postmaster processes to reload
-- end_ignore
